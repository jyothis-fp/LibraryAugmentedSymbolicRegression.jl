{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BIG-G_T=1_2b', 'PaLM_535b', 'BIG-G_T=1_2m', 'BIG-G_T=1_422m',\n",
       "       'BIG-G_sparse_2m', 'GPT_GPT-3_Medium', 'BIG-G_T=1_128b',\n",
       "       'BIG-G_T=0_16m', 'GPT_GPT-3_200B', 'BIG-G_sparse_8b',\n",
       "       'BIG-G_T=0_422m', 'GPT_GPT-3_Small', 'BIG-G_sparse_53m',\n",
       "       'BIG-G_T=0_53m', 'BIG-G_T=0_1b', 'BIG-G_sparse_125m',\n",
       "       'BIG-G_T=1_4b', 'BIG-G_sparse_4b', 'BIG-G_T=0_8b', 'BIG-G_T=1_53m',\n",
       "       'BIG-G_sparse_422m', 'BIG-G_T=1_27b', 'PaLM_64b', 'BIG-G_T=1_8b',\n",
       "       'BIG-G_T=0_27b', 'BIG-G_sparse_16m', 'PaLM_8b', 'BIG-G_T=0_2m',\n",
       "       'BIG-G_T=0_128b', 'BIG-G_T=0_244m', 'GPT_GPT-3_XL',\n",
       "       'BIG-G_T=0_125m', 'BIG-G_sparse_244m', 'BIG-G_sparse_2b',\n",
       "       'BIG-G_T=0_2b', 'BIG-G_T=1_244m', 'GPT_GPT-3_Large',\n",
       "       'GPT_GPT-3_3B', 'BIG-G_T=1_16m', 'BIG-G_sparse_1b',\n",
       "       'BIG-G_T=1_125m', 'BIG-G_T=0_4b', 'GPT_GPT-3_6B', 'BIG-G_T=1_1b',\n",
       "       'GPT_GPT-3_13B', 'Gopher_44M', 'Gopher_280B', 'Gopher_417M',\n",
       "       'Gopher_117M', 'Gopher_1.4B', 'Gopher_7.1B', 'T0_T0', 'T0++_T0++',\n",
       "       'T5-LM_T5-LM', 'T0+_T0+'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"csvs/bigbench_newschema.csv\")['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 43049 Test size 10763\n",
      "|                      |   number_of_shots |   temperature |   non_embedding_params |   total_params |   training_batch_size |   training_steps |        score |\n",
      "|:---------------------|------------------:|--------------:|-----------------------:|---------------:|----------------------:|-----------------:|-------------:|\n",
      "| number_of_shots      |       1           |  -0.00434305  |           -0.000665014 |   -0.000666343 |           -0.00130321 |      -0.00282396 |  0.0389363   |\n",
      "| temperature          |      -0.00434305  |   1           |           -0.0221554   |   -0.0217895   |           -0.207801   |       0.244261   | -0.000988636 |\n",
      "| non_embedding_params |      -0.000665014 |  -0.0221554   |            1           |    0.999999    |            0.513901   |       0.419474   |  0.151035    |\n",
      "| total_params         |      -0.000666343 |  -0.0217895   |            0.999999    |    1           |            0.512993   |       0.419991   |  0.151097    |\n",
      "| training_batch_size  |      -0.00130321  |  -0.207801    |            0.513901    |    0.512993    |            1          |      -0.338845   |  0.0787068   |\n",
      "| training_steps       |      -0.00282396  |   0.244261    |            0.419474    |    0.419991    |           -0.338845   |       1          |  0.0481215   |\n",
      "| score                |       0.0389363   |  -0.000988636 |            0.151035    |    0.151097    |            0.0787068  |       0.0481215  |  1           |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_shots</th>\n",
       "      <th>temperature</th>\n",
       "      <th>non_embedding_params</th>\n",
       "      <th>total_params</th>\n",
       "      <th>training_batch_size</th>\n",
       "      <th>training_steps</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53812.000000</td>\n",
       "      <td>53812.000000</td>\n",
       "      <td>5.381200e+04</td>\n",
       "      <td>5.381200e+04</td>\n",
       "      <td>5.381200e+04</td>\n",
       "      <td>5.381200e+04</td>\n",
       "      <td>53812.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.477997</td>\n",
       "      <td>0.289601</td>\n",
       "      <td>1.665473e+10</td>\n",
       "      <td>1.671633e+10</td>\n",
       "      <td>4.764267e+05</td>\n",
       "      <td>6.933628e+05</td>\n",
       "      <td>0.360767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.123665</td>\n",
       "      <td>0.453581</td>\n",
       "      <td>4.101677e+10</td>\n",
       "      <td>4.105028e+10</td>\n",
       "      <td>6.584038e+05</td>\n",
       "      <td>4.934638e+05</td>\n",
       "      <td>0.190447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.098048e+06</td>\n",
       "      <td>1.029005e+07</td>\n",
       "      <td>2.621440e+05</td>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.181238e+08</td>\n",
       "      <td>2.345078e+08</td>\n",
       "      <td>2.621440e+05</td>\n",
       "      <td>5.000000e+05</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.300000e+09</td>\n",
       "      <td>1.300000e+09</td>\n",
       "      <td>2.621440e+05</td>\n",
       "      <td>5.210000e+05</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.590103e+09</td>\n",
       "      <td>8.721175e+09</td>\n",
       "      <td>2.621440e+05</td>\n",
       "      <td>6.492000e+05</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+11</td>\n",
       "      <td>2.000000e+11</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>2.571500e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_shots   temperature  non_embedding_params  total_params  \\\n",
       "count     53812.000000  53812.000000          5.381200e+04  5.381200e+04   \n",
       "mean          1.477997      0.289601          1.665473e+10  1.671633e+10   \n",
       "std           1.123665      0.453581          4.101677e+10  4.105028e+10   \n",
       "min           0.000000      0.000000          2.098048e+06  1.029005e+07   \n",
       "25%           0.000000      0.000000          2.181238e+08  2.345078e+08   \n",
       "50%           1.000000      0.000000          1.300000e+09  1.300000e+09   \n",
       "75%           2.000000      1.000000          8.590103e+09  8.721175e+09   \n",
       "max           3.000000      1.000000          2.000000e+11  2.000000e+11   \n",
       "\n",
       "       training_batch_size  training_steps         score  \n",
       "count         5.381200e+04    5.381200e+04  53812.000000  \n",
       "mean          4.764267e+05    6.933628e+05      0.360767  \n",
       "std           6.584038e+05    4.934638e+05      0.190447  \n",
       "min           2.621440e+05    7.500000e+04      0.000000  \n",
       "25%           2.621440e+05    5.000000e+05      0.222222  \n",
       "50%           2.621440e+05    5.210000e+05      0.333333  \n",
       "75%           2.621440e+05    6.492000e+05      0.500000  \n",
       "max           4.000000e+06    2.571500e+06      1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv = \n",
    "df = pd.read_csv('csvs/bigbench_newschema_preferred_mcq_grade.csv')\n",
    "# drop null rows\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna()\n",
    "# df = df[df['number_of_shots'].isin([0, 1, 2, 3])]\n",
    "train_df = df.sample(int(0.8 * len(df)))\n",
    "test_df = df.drop(train_df.index)\n",
    "numerical_df = df[['number_of_shots', 'temperature', 'non_embedding_params', 'total_params', 'training_batch_size', 'training_steps', 'score']]\n",
    "print(\"Train size\", len(train_df), \"Test size\", len(test_df))\n",
    "print(numerical_df.corr().to_markdown())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_eqn1 = 'constant_1 + (constant_2 / (training_steps ^ number_of_shots))'\n",
    "str_eqn2 = 'constant_1 + (constant_2 / ((training_steps / constant_3) ^ number_of_shots))'\n",
    "str_chinchilla = '(constant_1 / ((training_steps * training_batch_size) ^ constant_2)) + (constant_3 / (total_params ^ constant_4)) + constant_5'\n",
    "str_chinchilla_ablation1 = '(constant_1 / ((training_steps * training_batch_size) ^ constant_2)) + constant_3'\n",
    "str_chinchilla_ablation2 = '(constant_1 / (total_params ^ constant_2)) + constant_3'\n",
    "str_chinchilla_ablate_numer = '(1 / ((training_steps * training_batch_size) ^ constant_1)) + (1 / (total_params ^ constant_2)) + constant_3'\n",
    "str_chinchilla_ablate_denom = '(constant_1 / (training_steps * training_batch_size)) + (constant_2 / (total_params)) + constant_3'\n",
    "str_modified_chinchilla = '(constant_1 / ((training_steps * training_batch_size) ^ (constant_2 * number_of_shots))) + (constant_3 / (total_params ^ constant_4)) + constant_5'\n",
    "\n",
    "def eqn1(x, constant_1, constant_2):\n",
    "    training_steps, number_of_shots = x\n",
    "    return constant_1 + (constant_2 / (training_steps ** number_of_shots))\n",
    "\n",
    "def eqn2(x, constant_1, constant_2, constant_3):\n",
    "    training_steps, number_of_shots = x\n",
    "    return constant_1 + (constant_2 / ((training_steps / constant_3) ** number_of_shots))\n",
    "\n",
    "def chinchilla(x, constant_1, constant_2, constant_3, constant_4, constant_5):\n",
    "    training_steps, number_of_shots, total_params, training_batch_size = x\n",
    "    return (constant_1 / ((training_steps * training_batch_size) ** constant_2)) + (constant_3 / (total_params ** constant_4)) + constant_5\n",
    "\n",
    "def chinchilla_ablation1(x, constant_1, constant_2, constant_3):\n",
    "    training_steps, number_of_shots, total_params, training_batch_size = x\n",
    "    return (constant_1 / ((training_steps * training_batch_size) ** constant_2)) + constant_3\n",
    "\n",
    "def chinchilla_ablation2(x, constant_1, constant_2, constant_3):\n",
    "    training_steps, number_of_shots, total_params, training_batch_size = x\n",
    "    return (constant_1 / (total_params ** constant_2)) + constant_3\n",
    "\n",
    "def chinchilla_ablate_numer(x, constant_1, constant_2, constant_3):\n",
    "    training_steps, number_of_shots, total_params, training_batch_size = x\n",
    "    return (1 / ((training_steps * training_batch_size) ** constant_1)) + (1 / (total_params ** constant_2)) + constant_3\n",
    "\n",
    "def chinchilla_ablate_denom(x, constant_1, constant_2, constant_3):\n",
    "    training_steps, number_of_shots, total_params, training_batch_size = x\n",
    "    return (constant_1 / (training_steps * training_batch_size)) + (constant_2 / total_params) + constant_3\n",
    "\n",
    "def modified_chinchilla(x, constant_1, constant_2, constant_3, constant_4, constant_5):\n",
    "    training_steps, number_of_shots, total_params, training_batch_size = x\n",
    "    return (constant_1 / ((training_steps * training_batch_size) ** (constant_2 * number_of_shots))) + (constant_3 / (total_params ** constant_4)) + constant_5\n",
    "\n",
    "x = np.vstack([\n",
    "    train_df['training_steps'].values,\n",
    "    train_df['number_of_shots'].values,\n",
    "])\n",
    "\n",
    "wide_x = np.vstack([\n",
    "    train_df['training_steps'].values,\n",
    "    train_df['number_of_shots'].values,\n",
    "    train_df['total_params'].values,\n",
    "    train_df['training_batch_size'].values,\n",
    "])\n",
    "bounds = (\n",
    "    [-np.inf, 0, -np.inf, 0, -np.inf],\n",
    "    [np.inf, np.inf, np.inf, np.inf, np.inf]\n",
    ")\n",
    "\n",
    "y = train_df['score'].values\n",
    "\n",
    "# This fits without a monotonicity constraint. The solution usually devolves into a degenerate solution with flip-flopping constants.\n",
    "# instead we're going to add a monotonicity constraint to fit the parameters.\n",
    "# popt1, pcov1, infodict1, mesg1, ier1 = curve_fit(eqn1, x, y, full_output=True)\n",
    "# popt2, pcov2, infodict2, mesg2, ier2 = curve_fit(eqn2, x, y, full_output=True)\n",
    "# popt3, pcov3, infodict3, mesg3, ier3 = curve_fit(chinchilla, wide_x, y, full_output=True, bounds=bounds)\n",
    "# popt4, pcov4, infodict4, mesg4, ier4 = curve_fit(modified_chinchilla, wide_x, y, full_output=True, bounds=bounds)\n",
    "# popt5, pcov5, infodict5, mesg5, ier5 = curve_fit(chinchilla_ablation1, wide_x, y, full_output=True, bounds=(bounds[0][2:], bounds[1][2:]))\n",
    "# popt6, pcov6, infodict6, mesg6, ier6 = curve_fit(chinchilla_ablation2, wide_x, y, full_output=True, bounds=(bounds[0][2:], bounds[1][2:]))\n",
    "# popt7, pcov7, infodict7, mesg7, ier7 = curve_fit(chinchilla_ablate_numer, wide_x, y, full_output=True, bounds=([0, 0, -np.inf], [np.inf, np.inf, np.inf]))\n",
    "# popt8, pcov8, infodict8, mesg8, ier8 = curve_fit(chinchilla_ablate_denom, wide_x, y, full_output=True, bounds=([-np.inf, -np.inf, -np.inf], [np.inf, np.inf, np.inf]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def monotonic_objective(predictor, mix=0.65):\n",
    "    def fn1(params, xdata, ydata):\n",
    "        \"\"\"\n",
    "        x[0] is the training steps.\n",
    "        We penalize the model for not being monotonicically increasing with respect to training steps.\n",
    "        \"\"\"\n",
    "        predicted = predictor(xdata, *params)\n",
    "        p = np.array(predicted[np.argsort(x[0])])\n",
    "        diff = p[1:] - p[:-1]\n",
    "        valid_diff = diff[diff < 0]\n",
    "        monotonic_increase = 0.0 if not len(valid_diff) else valid_diff.mean()\n",
    "\n",
    "        error = (np.sum((ydata - predicted)**2)) # RMSE loss\n",
    "        return ((1 - mix) * error) + (mix * monotonic_increase)\n",
    "    return fn1\n",
    "\n",
    "kwargs = dict(\n",
    "    options=dict(disp=False, maxiter=1000),\n",
    "    method='BFGS',\n",
    ")\n",
    "popt1 = minimize(monotonic_objective(eqn1), x0=np.array([0.363219, -0.015540]), args=(x, y), **kwargs).x\n",
    "popt2 = minimize(monotonic_objective(eqn2), x0=np.array([0.363219, -0.015540, 12605]), args=(x, y), **kwargs).x\n",
    "popt3 = minimize(monotonic_objective(chinchilla), x0=np.array([1., 0.99983365, 0.8788157 , 3.13948064, 0.36130033]), args=(wide_x, y), **kwargs).x\n",
    "popt4 = minimize(monotonic_objective(modified_chinchilla), x0=np.array([-0.02186013,  1.00041618,  0.89328067,  2.88247603,  0.36694853]), args=(wide_x, y), **kwargs).x\n",
    "popt5 = minimize(monotonic_objective(chinchilla_ablation1), x0=np.array([1.        , 1.        , 0.36130362]), args=(wide_x, y), **kwargs).x\n",
    "popt6 = minimize(monotonic_objective(chinchilla_ablation2), x0=np.array([0.90374502, 2.6071086 , 0.3613004 ]), args=(wide_x, y), **kwargs).x\n",
    "popt7 = minimize(monotonic_objective(chinchilla_ablate_numer), x0=np.array([0.99987481, 2.60998853, 0.3613004 ]), args=(wide_x, y), **kwargs).x\n",
    "popt8 = minimize(monotonic_objective(chinchilla_ablate_denom), x0=np.array([ 4.93647189e-01, -6.20734318e+05,  3.66433551e-01]), args=(wide_x, y), **kwargs).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted eqn1:  0.3658399805958976 + (-0.019393646403258875 / (training_steps ^ number_of_shots))\n",
      "Fitted eqn2:  0.36586570526070605 + (-0.018970864489142484 / ((training_steps / 12604.999990734193) ^ number_of_shots))\n",
      "Fitted chinchilla:  (1.0 / ((training_steps * training_batch_size) ^ 0.99983365)) + (0.8788157 / (total_params ^ 3.13948064)) + 0.3607812867216579\n",
      "Fitted modified chinchilla:  (-0.019404684047361738 / ((training_steps * training_batch_size) ^ (1.00041618 * number_of_shots))) + (0.89328067 / (total_params ^ 2.88247603)) + 0.36584284907725884\n",
      "Fitted chinchilla_ablation1:  (1.0 / ((training_steps * training_batch_size) ^ 1.0)) + 0.36078128665874637\n",
      "Fitted chinchilla_ablation2:  (0.90374502 / (total_params ^ 2.6071086)) + 0.3607812868426495\n",
      "Fitted chinchilla_ablate_numer:  (1 / ((training_steps * training_batch_size) ^ 0.99987481)) + (1 / (total_params ^ 2.60998853)) + 0.3607812868467931\n",
      "Fitted chinchilla_ablate_denom:  (0.493647189 / (training_steps * training_batch_size)) + (-620734.3180000606 / (total_params)) + 0.3659119062895185\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "# display equation with constants as math\n",
    "# fitted_eqn = eqn\n",
    "# for i, constant in enumerate(popt):\n",
    "#     fitted_eqn = fitted_eqn.replace('constant_{}'.format(i+1), str(constant))\n",
    "def fit_eqn(popt, eqn):\n",
    "    fitted_eqn = eqn\n",
    "    for i, constant in enumerate(popt):\n",
    "        fitted_eqn = fitted_eqn.replace('constant_{}'.format(i+1), str(constant))\n",
    "    return fitted_eqn\n",
    "\n",
    "str_fitted_eqn1 = fit_eqn(popt1, str_eqn1)\n",
    "str_fitted_eqn2 = fit_eqn(popt2, str_eqn2)\n",
    "str_fitted_chinchilla = fit_eqn(popt3, str_chinchilla)\n",
    "str_fitted_modified_chinchilla = fit_eqn(popt4, str_modified_chinchilla)\n",
    "str_fitted_chinchilla_ablation1 = fit_eqn(popt5, str_chinchilla_ablation1)\n",
    "str_fitted_chinchilla_ablation2 = fit_eqn(popt6, str_chinchilla_ablation2)\n",
    "str_fitted_chinchilla_ablate_numer = fit_eqn(popt7, str_chinchilla_ablate_numer)\n",
    "str_fitted_chinchilla_ablate_denom = fit_eqn(popt8, str_chinchilla_ablate_denom)\n",
    "print(\"Fitted eqn1: \", str_fitted_eqn1)\n",
    "print(\"Fitted eqn2: \", str_fitted_eqn2)\n",
    "print(\"Fitted chinchilla: \", str_fitted_chinchilla)\n",
    "print(\"Fitted modified chinchilla: \", str_fitted_modified_chinchilla)\n",
    "print(\"Fitted chinchilla_ablation1: \", str_fitted_chinchilla_ablation1)\n",
    "print(\"Fitted chinchilla_ablation2: \", str_fitted_chinchilla_ablation2)\n",
    "print(\"Fitted chinchilla_ablate_numer: \", str_fitted_chinchilla_ablate_numer)\n",
    "print(\"Fitted chinchilla_ablate_denom: \", str_fitted_chinchilla_ablate_denom)\n",
    "\n",
    "\n",
    "fitted_eqn_1 = partial(eqn1, constant_1=popt1[0], constant_2=popt1[1])\n",
    "fitted_eqn_2 = partial(eqn2, constant_1=popt2[0], constant_2=popt2[1], constant_3=popt2[2])\n",
    "fitted_chinchilla = partial(chinchilla, constant_1=popt3[0], constant_2=popt3[1], constant_3=popt3[2], constant_4=popt3[3], constant_5=popt3[4])\n",
    "fitted_modified_chinchilla = partial(modified_chinchilla, constant_1=popt4[0], constant_2=popt4[1], constant_3=popt4[2], constant_4=popt4[3], constant_5=popt4[4])\n",
    "fitted_chinchilla_ablation1 = partial(chinchilla_ablation1, constant_1=popt5[0], constant_2=popt5[1], constant_3=popt5[2])\n",
    "fitted_chinchilla_ablation2 = partial(chinchilla_ablation2, constant_1=popt6[0], constant_2=popt6[1], constant_3=popt6[2])\n",
    "fitted_chinchilla_ablate_numer = partial(chinchilla_ablate_numer, constant_1=popt7[0], constant_2=popt7[1], constant_3=popt7[2])\n",
    "fitted_chinchilla_ablate_denom = partial(chinchilla_ablate_denom, constant_1=popt8[0], constant_2=popt8[1], constant_3=popt8[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(y - y_pred)^2                 <1e-07   <1e-05   <0.1     <1       <inf     mean     variance\n",
      "eqn1                           4        39       9889     831      0       0.03643  0.00281 \n",
      "eqn2                           5        41       9886     831      0       0.03644  0.00281 \n",
      "chinchilla                     4        63       9931     765      0       0.03656  0.00284 \n",
      "modified_chinchilla            4        39       9889     831      0       0.03643  0.00281 \n",
      "chinchilla_ablation1           4        63       9931     765      0       0.03656  0.00284 \n",
      "chinchilla_ablation2           4        63       9931     765      0       0.03656  0.00284 \n",
      "chinchilla_ablate_numer        4        63       9931     765      0       0.03656  0.00284 \n",
      "chinchilla_ablate_denom        3        47       9941     772      0       0.03643  0.00278 \n"
     ]
    }
   ],
   "source": [
    "# get loss for each equation on the dataset\n",
    "\n",
    "buckets = [0, 1e-7, 1e-5, 1e-1, 1, np.inf]\n",
    "\n",
    "def get_loss(fitted_eqn, x, y):\n",
    "    y_pred = fitted_eqn(x)\n",
    "    diff = (y - y_pred) ** 2\n",
    "    bucketed_loss = [0] * (len(buckets) - 1)\n",
    "    for i in range(len(buckets) - 1):\n",
    "        bucketed_loss[i] = len((diff[(diff > buckets[i]) & (diff <= buckets[i+1])]))\n",
    "    return bucketed_loss, np.mean(diff), np.var(diff)\n",
    "\n",
    "\n",
    "test_x = np.vstack([\n",
    "    test_df['training_steps'].values,\n",
    "    test_df['number_of_shots'].values,\n",
    "])\n",
    "test_wide_x = np.vstack([\n",
    "    test_df['training_steps'].values,\n",
    "    test_df['number_of_shots'].values,\n",
    "    test_df['total_params'].values,\n",
    "    test_df['training_batch_size'].values,\n",
    "])\n",
    "\n",
    "test_y = test_df['score'].values\n",
    "\n",
    "loss1 = get_loss(fitted_eqn_1, test_x, test_y)\n",
    "loss2 = get_loss(fitted_eqn_2, test_x, test_y)\n",
    "loss3 = get_loss(fitted_chinchilla, test_wide_x, test_y)\n",
    "loss4 = get_loss(fitted_modified_chinchilla, test_wide_x, test_y)\n",
    "loss5 = get_loss(fitted_chinchilla_ablation1, test_wide_x, test_y)\n",
    "loss6 = get_loss(fitted_chinchilla_ablation2, test_wide_x, test_y)\n",
    "loss7 = get_loss(fitted_chinchilla_ablate_numer, test_wide_x, test_y)\n",
    "loss8 = get_loss(fitted_chinchilla_ablate_denom, test_wide_x, test_y)\n",
    "row_name = ['eqn1', 'eqn2', 'chinchilla', 'modified_chinchilla', 'chinchilla_ablation1', 'chinchilla_ablation2', 'chinchilla_ablate_numer', 'chinchilla_ablate_denom']\n",
    "rows = [loss1, loss2, loss3, loss4, loss5, loss6, loss7, loss8]\n",
    "\n",
    "\n",
    "header = ['<' + str(b) for b in buckets[1:]] + ['mean', 'variance']\n",
    "print('{:<31}'.format('(y - y_pred)^2') + ' '.join([f'{k:<8}' for k in header]))\n",
    "for i, (buckets, mean, variance) in enumerate(rows):\n",
    "    print('{:<30}'.format(row_name[i]), ' '.join([f'{k:<8}' for k in buckets])+ f'{mean:<8.5f} {variance:<8.5f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lasr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
